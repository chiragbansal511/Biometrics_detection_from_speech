{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02f181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\inspect.py:992: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "C:\\Users\\Chirag Bansal\\AppData\\Local\\Temp\\ipykernel_25264\\357805439.py:8: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import SpeakerRecognition\n",
      "c:\\Python311\\Lib\\site-packages\\speechbrain\\utils\\autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "c:\\Python311\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
      "  warnings.warn(\n",
      "100%|██████████| 13509/13509 [1:38:49<00:00,  2.28it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Notebook 1: extract_features_part1.ipynb\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "\n",
    "# --------- Load CSV & Prepare Partial Data ---------\n",
    "df = pd.read_csv(\"D:/Projects/speech_project/other.csv\")\n",
    "df = df[['client_id', 'path']].dropna()\n",
    "df['full_path'] = df['path'].apply(lambda x: os.path.join(\"D:/Projects/speech_project/clips\", x))\n",
    "df = df[df['full_path'].apply(os.path.exists)]\n",
    "\n",
    "# Keep speakers with at least 2 clips\n",
    "speaker_counts = df['client_id'].value_counts()\n",
    "df = df[df['client_id'].isin(speaker_counts[speaker_counts >= 2].index)]\n",
    "\n",
    "# Encode labels\n",
    "label_to_id = {label: idx for idx, label in enumerate(sorted(df['client_id'].unique()))}\n",
    "df['label'] = df['client_id'].map(label_to_id)\n",
    "\n",
    "# Take first half\n",
    "df_part = df.iloc[len(df)//2:]  # Instead of the first half\n",
    "\n",
    "# --------- Load ECAPA-TDNN Model ---------\n",
    "speaker_model = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"speechbrain_model\")\n",
    "\n",
    "# --------- Feature Extraction ---------\n",
    "def extract_embedding(audio_path, sample_rate=16000, duration=3.0):\n",
    "    waveform, sr = torchaudio.load(audio_path)\n",
    "    waveform = torchaudio.transforms.Resample(sr, sample_rate)(waveform.mean(dim=0))\n",
    "    fixed_len = int(sample_rate * duration)\n",
    "    if waveform.size(0) < fixed_len:\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, fixed_len - waveform.size(0)))\n",
    "    else:\n",
    "        waveform = waveform[:fixed_len]\n",
    "    with torch.no_grad():\n",
    "        return speaker_model.encode_batch(waveform.unsqueeze(0)).squeeze().numpy()\n",
    "\n",
    "# --------- Extract & Save ---------\n",
    "features, labels = [], []\n",
    "for _, row in tqdm(df_part.iterrows(), total=len(df_part)):\n",
    "    try:\n",
    "        emb = extract_embedding(row['full_path'])\n",
    "        features.append(emb)\n",
    "        labels.append(row['label'])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {row['full_path']} - {e}\")\n",
    "\n",
    "# Save to disk (append mode)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "if os.path.exists(\"features.npy\"):\n",
    "    prev_feat = np.load(\"features.npy\")\n",
    "    prev_lab = np.load(\"labels.npy\")\n",
    "    features = np.concatenate([prev_feat, features])\n",
    "    labels = np.concatenate([prev_lab, labels])\n",
    "\n",
    "np.save(\"features.npy\", features)\n",
    "np.save(\"labels.npy\", labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
